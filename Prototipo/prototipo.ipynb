{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "##ML + STRUCTURED STREAMING\n",
    "\n",
    "#Costruzione di un modello ML e predizione in tempo reale sfruttando lo straming strutturato\n",
    "\n",
    "Il modello creato viene poi esportato per essere usato da uno script successivo\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#IMPORT\n",
    "import pyspark.ml.regression as rg\n",
    "import pyspark as pys \n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import pyspark.sql as sql\n",
    "import pyspark.sql.functions as f\n",
    "import pyspark.ml.feature as feat\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "import json \n",
    "\n",
    "\n",
    "import pyspark.ml.evaluation as ev\n",
    "\n",
    "#CONFIGURAZIONE PATH\n",
    "\n",
    "#File contente il dataset completo\n",
    "forest_path = 'forest_coverage_type.csv'\n",
    "#Directory in cui esportare il modello e lo schema nel file schema.json\n",
    "modelPath=\"/home/lorenzo/Documenti/PySpark-tesi/Prototipo/exported\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "#Inizializzazione spark session/context e caricamento dataset\n",
    "\n",
    "#Spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"StructuredNetworkWordCount\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#Spark context\n",
    "sc = spark.sparkContext\n",
    "\n",
    "#Caricamento dataset da file CSV\n",
    "\n",
    "forest=spark.read.csv(\n",
    "    forest_path,\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "print(\"Schema DF: \")\n",
    "forest.printSchema()\n",
    "\n",
    "#Divisione fra train e test\n",
    "forest_train, forest_test=(\n",
    "    forest.randomSplit([0.7,0.3],seed=123)\n",
    ")\n",
    "\n",
    "#Esporto il dataset di test in formato CSV (in un unico file con repartition(1))\n",
    "forest_test.repartition(1).write.csv(\"forest_test.csv\",\"overwrite\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Creazione modello di ML\n",
    "\n",
    "#Cerchiamo di predirre la colonna Elevation che è la prima nel dataset\n",
    "\n",
    "#Usiamo una pipeline in 2 stadi per la creazione di modelli ML in PySpark\n",
    "\n",
    "#1) Istanzione un oggetto della classe VectorAssembler\n",
    "#Che per permette di fondere tutte le colonne in una\n",
    "vectorAssembler = feat.VectorAssembler(\n",
    "    inputCols=forest.columns[1:] #la 1 è \"elevation\"\n",
    "    , outputCol='features'\n",
    "    )\n",
    "\n",
    "#2) Istanzione un oggetto della classe RandomForestRegressor\n",
    "#Implementa l'algoritmo di regressione \"Random Forest\" e crea il modello ML\n",
    "rf_obj = rg.RandomForestRegressor(\n",
    "    labelCol='Elevation' #target value (colonna da predire)\n",
    "    , maxDepth=10\n",
    "    , minInstancesPerNode=10\n",
    "    , minInfoGain=0.1\n",
    "    , numTrees=10\n",
    "    )\n",
    "\n",
    "#Pipeline \n",
    "pip = Pipeline(stages=[vectorAssembler, rf_obj])\n",
    "\n",
    "#Modello ML \n",
    "pModel = ( #DF come quello di input ma con le colonne features e predicition \n",
    "    pip.fit(forest_train)\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Esportazione dati\n",
    "\n",
    "#Salvo il modello ML ottenuto\n",
    "pModel.write().overwrite().save(modelPath)\n",
    "\n",
    "#Esporto lo schema del dataset forest\n",
    "\n",
    "with open(modelPath+\"/schema.json\", \"w\") as f:\n",
    "    json.dump(forest.schema.jsonValue(), f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Test del modello su forest_test (solo batch)\n",
    "results=(\n",
    "    pModel\n",
    "    .transform(forest_test)\n",
    "    .select(\"Elevation\",\"prediction\")\n",
    ")\n",
    "\n",
    "#5 predizioni di esempio (da forest_train)\n",
    "results.show(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Valutazione accuratezza \n",
    "evaluator = ev.RegressionEvaluator(labelCol='Elevation')\n",
    "evaluator.evaluate(results, {evaluator.metricName: 'r2'})"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}